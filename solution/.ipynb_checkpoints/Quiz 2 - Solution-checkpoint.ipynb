{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 2 Reference Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "**In principal component analysis, a smaller eigenvalue indicates that**\n",
    "\n",
    "**Answer**: A given **principal component**, say V_j, is **less** important.\n",
    "\n",
    "1. Each eigenvalue is associated with a principal component (eigenvector), not the variable in the original space.\n",
    "2. Smaller means less variation/information and hence less important.\n",
    "\n",
    "\n",
    "## Q2\n",
    "**We have a set of 20x20 binary images. We want to use PCA to reduce the dimensionality to 10. How many parameters do we need to estimate in total?**\n",
    "\n",
    "**Answer**: 4000\n",
    "\n",
    "1. 20x20 images mean the original dimensionality is 20x20=400\n",
    "2. To reduce the dimensionality to 10, we need to estimate 10 eigenvector.\n",
    "3. Each eigenvector is of dimension 400 so that total number of parameters to estimate is 400 x 10 = 4000\n",
    "\n",
    "\n",
    "\n",
    "## Q3\n",
    "**In slide 10 of Lecture 8, if all the variables are assumed to be Gaussian and there are 8 variables in total, how many parameters do we need to learn/compute?**\n",
    "\n",
    "**Answer**: 16\n",
    "\n",
    "1. Slide 10 of L8 assumes variables are independent.\n",
    "2. Each Gaussian variable needs two parameters.\n",
    "3. 8x2=16\n",
    "\n",
    "\n",
    "## Q4\n",
    "**Consider the fully connected neural network (Multilayer perceptron) in Slide 47 of Lecture 6. If we insert another new hidden layer with 8 neurons between the old Hidden layer with four neurons and the Output layer with 2 neurons, with full connections between the old hidden layer and new hidden layer, and full connections between new hidden layer and output layer (no direct connections between the old hidden layer and the output layer). The same activation function sigma is used in the new hidden layer. How many learnable parameters in total are there for this two-hidden-layer neural network?**\n",
    "\n",
    "**Answer**: 74\n",
    "\n",
    "Following the example in the slide\n",
    "1. Weights: 3*4+4*8+8*2=60\n",
    "2. Bias: 4+8+2=14\n",
    "3. 60 + 14 =74\n",
    "\n",
    "\n",
    "\n",
    "## Q5\n",
    "**You are given a training dataset with a 2x2 covariance matrix C = [1, 2; 3, 4], i.e., the first row is [1 2] and the second row is [3, 4]. This covariance matrix C has two eigenvectors u1=[-0.55 0.83]^T and u2=[0.83 0.55]^T and two corresponding eigenvalues 5 and 51. How much of the variance in the data is explained by the FIRST principal component? Please input your answer rounding to the nearest integer, e.g., input 12 if your answer is 12.34%.**\n",
    "\n",
    "**Answer**: 91\n",
    "\n",
    "51/(51+5)=0.91071428571\n",
    "\n",
    "\n",
    "## Q6\n",
    "**Please modify Lab 7B2 strictly following the three requirements from a client:**\n",
    "\n",
    "1) Specify a random seed of 2020 using the manual_seed() method of pytorch right before the line myAE=Autoencoder(). No any other seed at anywhere else, i.e., remove the previous seed torch.manual_seed(509) above criterion = nn.MSELoss();\n",
    "\n",
    "2) Change the optimizer to torch.optim.SGD with learning_rate=0.05 and other parameters as default;\n",
    "\n",
    "3) Train the autoencoder for at least three epochs, record the loss at the end of epoch 1 as loss1, and the loss at the end of epoch 3 as loss3. \n",
    "\n",
    "**Please report the improvement (loss1-loss3) using only three decimals with rounding, e.g., x.xxx.**\n",
    "\n",
    "**Answer**: See below. The improvement is 0.030788384, rounded to 0.031. I accept a tolerance of $\\pm$0.001 (likely rounding to the wrong number).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libaries\n",
    "\n",
    "Get ready by importing the standard APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "Let us work with the popular [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) with handwritten digits. We will work on a subset for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "4096\n"
     ]
    }
   ],
   "source": [
    "mnist_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(len(mnist_data))\n",
    "mnist_data = list(mnist_data)[:4096]\n",
    "print(len(mnist_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the NN architecture\n",
    "In Lab 1, we did not define a class for our linear regression NN. Here we do so and define an autoencoder class consisting of an **encoder** followed by a **decoder** as defined below.\n",
    "<img src=\"https://miro.medium.com/max/3524/1*oUbsOnYKX5DEpMOK3pH_lg.png\" style=\"width:360px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 1 input image channel, 16 output channel, 3x3 square convolution\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  #to range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`__init__()` defines the layers.  `forward()` defines the *forward pass* that transform the input to the output. `backward()` is automatically defined using `autograd`.\n",
    "\n",
    "Here, we have both convolution layers `Conv2d()` and transpose convolution layers `ConvTranspose2d()`, with nice illustrations at [Convolution arithmetic](https://github.com/vdumoulin/conv_arithmetic). The basic ones are reproduced below where blue maps indicate inputs, and cyan maps indicate outputs.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "    <td  style=\"text-align: left\"> Convolution with no padding, no strides.      <img src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_no_strides.gif\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "    <td  style=\"text-align: left\"> Transpose convolution with No padding, no strides.<img src=\"https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides_transposed.gif\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "`ReLu()` and `Sigmoid()` are [rectified linear unit (ReLU)](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) and [Sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function), two popular **activation function** that performs a *nonlinear* transformation/mapping of an input variable (element-wise operation).\n",
    "\n",
    "\n",
    "#### Inspect the NN architecture\n",
    "\n",
    "Now let's take a look at the autoencoder built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(64, 32, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Set the random seed for reproducibility \n",
    "torch.manual_seed(2020) \n",
    "\n",
    "myAE=Autoencoder()\n",
    "print(myAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the (randomly initialised) parameters of this NN. Below, we check the first 2D convolution and the ReLu activiation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "torch.Size([16, 1, 3, 3])\n",
      "torch.Size([16])\n",
      "Parameter containing:\n",
      "tensor([-0.1837, -0.2009, -0.1551, -0.1346,  0.0843,  0.0840, -0.2357, -0.0940,\n",
      "         0.2356, -0.1050,  0.2993, -0.1217,  0.2885,  0.1571, -0.0261,  0.2319],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "params = list(myAE.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # First Conv2d's .weight\n",
    "print(params[1].size())  # First Conv2d's .bias\n",
    "print(params[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about these functions, refer to the [`torch.nn` documentation](https://pytorch.org/docs/stable/nn.html) (search for the function, e.g., search for `torch.nn.ReLu(` and you will find its documentation [here](https://pytorch.org/docs/stable/nn.html?highlight=relu#torch.nn.ReLU)\n",
    "\n",
    "#### Train the NN\n",
    "Next, we will feed data in this autoencoder to train it, i.e., learn its parameters so that the reconstruction error (the `loss`) is minimised, using the mean square error (MSE) and `Adam` optimiser. The dataset is loaded in batches to train the model. One `epoch` means one cycle through the full training dataset. The `outputs` at the end of each epoch save the orignal image and the reconstructed (decoded) image pairs for later inspection. The steps are \n",
    "* Define the optimisation criteria and optimisation method.\n",
    "* Iterate through the whole dataset in batches, for a number of `epochs` till a maximum specified or a convergence criteria (e.g., successive change of loss < 0.000001)\n",
    "* In each batch processing, we \n",
    "    * do a forward pass\n",
    "    * compute the loss\n",
    "    * backpropagate the loss via `autograd`\n",
    "    * update the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.1385\n",
      "Epoch:2, Loss:0.1203\n",
      "Epoch:3, Loss:0.1077\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters for training\n",
    "batch_size=64\n",
    "learning_rate=0.05\n",
    "max_epochs = 3\n",
    "\n",
    "\n",
    "#Set the random seed for reproducibility \n",
    "#torch.manual_seed(509) \n",
    "#Choose mean square error loss\n",
    "criterion = nn.MSELoss() \n",
    "\n",
    "#Choose the SGD optimiser\n",
    "#optimizer = torch.optim.Adam(myAE.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "optimizer = torch.optim.SGD(myAE.parameters(), lr=learning_rate)\n",
    "\n",
    "#Specify how the data will be loaded in batches (with random shffling)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#Record loss\n",
    "allloss = []\n",
    "#Start training\n",
    "for epoch in range(max_epochs):\n",
    "    for data in train_loader:\n",
    "        img, label = data\n",
    "        optimizer.zero_grad()\n",
    "        recon = myAE(img)\n",
    "        loss = criterion(recon, img)\n",
    "        loss.backward()\n",
    "        optimizer.step()                \n",
    "    print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "    allloss.append((epoch, loss.data.numpy()),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030788384"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allloss[0][1]-allloss[max_epochs-1][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
